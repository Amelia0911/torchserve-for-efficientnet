2021-05-17 15:51:24,875 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.3.1
TS Home: /home/oem/Disk/0-software/miniconda3/envs/serve-g/lib/python3.8/site-packages
Current directory: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 8
Max heap size: 1940 M
Python executable: /home/oem/Disk/0-software/miniconda3/envs/serve-g/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/model-store
Initial Models: efficientnet-b1.mar
Log dir: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/logs
Metrics dir: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2021-05-17 15:51:24,904 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: efficientnet-b1.mar
2021-05-17 15:51:25,285 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 0c492d480d0f430db3335e64e0714321
2021-05-17 15:51:25,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model efficientnet-b1
2021-05-17 15:51:25,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model efficientnet-b1
2021-05-17 15:51:25,294 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model efficientnet-b1 loaded.
2021-05-17 15:51:25,294 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: efficientnet-b1, count: 1
2021-05-17 15:51:25,303 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2021-05-17 15:51:25,396 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-05-17 15:51:25,397 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2021-05-17 15:51:25,398 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-05-17 15:51:25,398 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2021-05-17 15:51:25,399 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-05-17 15:51:25,420 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2021-05-17 15:51:25,421 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]24588
2021-05-17 15:51:25,421 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2021-05-17 15:51:25,421 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.8.8
2021-05-17 15:51:25,421 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change null -> WORKER_STARTED
2021-05-17 15:51:25,426 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2021-05-17 15:51:25,449 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2021-05-17 15:51:28,149 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2674
2021-05-17 15:51:28,149 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-05-17 15:51:41,068 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - device:  cuda:0
2021-05-17 15:51:41,068 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - probs =  [[0.5412943363189697, 0.0863814428448677, 0.02064180001616478, 0.01820545271039009, 0.016243722289800644]]
2021-05-17 15:51:41,068 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2021-05-17 15:51:41,068 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - classes =  [[948, 954, 957, 931, 949]]
2021-05-17 15:51:41,070 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.job.Job - Waiting time ns: 136846, Backend time ns: 166981401
2021-05-17 15:53:18,933 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - device:  cuda:0
2021-05-17 15:53:18,934 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291
2021-05-17 15:53:18,934 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - probs =  [[0.6616447567939758, 0.13378049433231354, 0.09632444381713867, 0.006356021389365196, 0.005184500478208065]]
2021-05-17 15:53:18,934 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - classes =  [[281, 285, 282, 700, 283]]
2021-05-17 15:53:18,934 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.job.Job - Waiting time ns: 75075, Backend time ns: 2291381917
2021-05-17 16:02:12,757 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-05-17 16:02:12,758 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-05-17 16:02:12,758 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-05-17 16:02:14,777 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-05-17 16:02:14,791 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model efficientnet-b1 version 1.0
2021-05-17 16:02:14,791 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: efficientnet-b1 version: 1.0
2021-05-17 16:02:14,792 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-05-17 16:02:14,792 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stderr
2021-05-17 16:02:14,792 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:02:14,792 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-05-17 16:02:14,792 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-05-17 16:02:14,792 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-05-17 16:02:14,793 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-05-17 16:02:14,793 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Frontend disconnected.
2021-05-17 16:02:14,793 [WARN ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stderr
2021-05-17 16:02:14,793 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:02:14,793 [WARN ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:02:14,793 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-05-17 16:02:14,800 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model efficientnet-b1 unregistered.
2021-05-17 16:02:24,313 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.3.1
TS Home: /home/oem/Disk/0-software/miniconda3/envs/serve-g/lib/python3.8/site-packages
Current directory: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 8
Max heap size: 1940 M
Python executable: /home/oem/Disk/0-software/miniconda3/envs/serve-g/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/model-store
Initial Models: efficientnet-b1.mar
Log dir: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/logs
Metrics dir: /home/oem/Disk/1-WorkFolder/0-mywork/github/torchserve-for-efficientnet/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2021-05-17 16:02:24,338 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: efficientnet-b1.mar
2021-05-17 16:02:24,718 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 9d9c1a10d014456598c98e57407caf34
2021-05-17 16:02:24,725 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model efficientnet-b1
2021-05-17 16:02:24,725 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model efficientnet-b1
2021-05-17 16:02:24,725 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model efficientnet-b1 loaded.
2021-05-17 16:02:24,726 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: efficientnet-b1, count: 1
2021-05-17 16:02:24,735 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2021-05-17 16:02:24,834 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-05-17 16:02:24,835 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2021-05-17 16:02:24,836 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-05-17 16:02:24,836 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2021-05-17 16:02:24,837 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-05-17 16:02:24,838 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2021-05-17 16:02:24,839 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]26437
2021-05-17 16:02:24,839 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2021-05-17 16:02:24,839 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.8.8
2021-05-17 16:02:24,839 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change null -> WORKER_STARTED
2021-05-17 16:02:24,843 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2021-05-17 16:02:24,853 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2021-05-17 16:02:27,619 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2726
2021-05-17 16:02:27,619 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-05-17 16:02:28,907 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - device:  cuda:0
2021-05-17 16:02:28,907 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - probs =  [[0.6616447567939758, 0.13378049433231354, 0.09632444381713867, 0.006356021389365196, 0.005184500478208065]]
2021-05-17 16:02:28,907 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - classes =  [[281, 285, 282, 700, 283]]
2021-05-17 16:02:28,907 [INFO ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 145
2021-05-17 16:02:28,909 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.job.Job - Waiting time ns: 146164, Backend time ns: 147908611
2021-05-17 16:07:27,548 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2021-05-17 16:07:27,548 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2021-05-17 16:07:27,549 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2021-05-17 16:07:29,575 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-05-17 16:07:29,579 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model efficientnet-b1 version 1.0
2021-05-17 16:07:29,579 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: efficientnet-b1 version: 1.0
2021-05-17 16:07:29,580 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_MODEL_LOADED -> WORKER_SCALED_DOWN
2021-05-17 16:07:29,580 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stderr
2021-05-17 16:07:29,580 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:07:29,580 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-05-17 16:07:29,581 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Frontend disconnected.
2021-05-17 16:07:29,581 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-05-17 16:07:29,581 [INFO ] W-9000-efficientnet-b1_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:07:29,581 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-05-17 16:07:29,582 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-efficientnet-b1_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-05-17 16:07:29,582 [WARN ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stderr
2021-05-17 16:07:29,582 [WARN ] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-efficientnet-b1_1.0-stdout
2021-05-17 16:07:29,582 [DEBUG] W-9000-efficientnet-b1_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-05-17 16:07:29,588 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model efficientnet-b1 unregistered.
